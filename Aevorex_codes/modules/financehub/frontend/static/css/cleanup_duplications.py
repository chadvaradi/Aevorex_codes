#!/usr/bin/env python3
"""
SZISZTEMATIKUS CSS DUPLIK√ÅCI√ì CLEANUP
Benchmark: teljes_duplikacio_lista.txt (555 duplik√°ci√≥ ‚Üí 0)
"""

import re
import os
import shutil
from pathlib import Path
from collections import defaultdict

class DuplicationCleaner:
    """Szisztematikus duplik√°ci√≥ tiszt√≠t√≥"""
    
    def __init__(self):
        self.base_dir = Path(".")
        self.backup_dir = Path("backup_before_cleanup")
        self.progress_file = "cleanup_progress.txt"
        self.benchmark_file = "teljes_duplikacio_lista.txt"
        
    def create_backup(self):
        """Biztons√°gi ment√©s k√©sz√≠t√©se"""
        if self.backup_dir.exists():
            shutil.rmtree(self.backup_dir)
        
        print("üîÑ Biztons√°gi ment√©s k√©sz√≠t√©se...")
        shutil.copytree(".", self.backup_dir, ignore=shutil.ignore_patterns(
            "*.pyc", "__pycache__", "backup_*", "*.log", "teljes_duplikacio_lista.txt"
        ))
        print("‚úÖ Backup k√©sz!")
    
    def get_current_benchmark(self):
        """Aktu√°lis benchmark beolvas√°sa"""
        try:
            with open(self.benchmark_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Duplik√°ci√≥k sz√°m√°nak kinyer√©se
            match = re.search(r'üìä Val√≥di duplik√°ci√≥k: (\d+)', content)
            if match:
                return int(match.group(1))
            return 0
        except:
            return 0
    
    def regenerate_benchmark(self):
        """Benchmark √∫jragener√°l√°sa"""
        print("üîÑ Benchmark √∫jragener√°l√°sa...")
        os.system("python3 show_all_duplications.py > teljes_duplikacio_lista.txt 2>&1")
        return self.get_current_benchmark()
    
    def fix_cross_file_duplications(self):
        """Cross-file duplik√°ci√≥k jav√≠t√°sa - PRIORIT√ÅS 1"""
        print("\nüî¥ PRIORIT√ÅS 1: Cross-file duplik√°ci√≥k jav√≠t√°sa")
        
        # Legkritikusabb duplik√°ci√≥k
        critical_fixes = [
            {
                'selector': '.price-change',
                'keep_file': '01-base/typography.css',
                'remove_from': [
                    '03-layout/app-container.css',
                    '03-layout/main-content.css',
                    '02-shared/fonts.css',
                    '04-components/stock-header/stock-header.css',
                    '04-components/widgets/financial-widgets.css',
                    '04-components/stock-header/price-display/price-display-main.css'
                ]
            },
            {
                'selector': '.content-wrapper',
                'keep_file': '03-layout/app-layout.css',
                'remove_from': [
                    '03-layout/app-container.css',
                    '03-layout/main-content.css'
                ]
            },
            {
                'selector': '.status-indicator',
                'keep_file': '03-layout/nav-main.css',
                'remove_from': [
                    '03-layout/main-content.css',
                    '04-components/widgets/financial-widgets.css'
                ]
            },
            {
                'selector': '.hidden',
                'keep_file': '02-shared/utilities.css',
                'remove_from': [
                    '03-layout/app-container.css',
                    '01-base/global.css',
                    '04-components/core.css'
                ]
            },
            {
                'selector': '.dropdown-menu',
                'keep_file': '03-layout/nav-main.css',
                'remove_from': [
                    '04-components/chart/controls.css'
                ]
            },
            {
                'selector': '.dropdown-item',
                'keep_file': '03-layout/nav-main.css',
                'remove_from': [
                    '04-components/chart/controls.css'
                ]
            }
        ]
        
        for fix in critical_fixes:
            self._apply_cross_file_fix(fix)
    
    def _apply_cross_file_fix(self, fix_config):
        """Egy cross-file duplik√°ci√≥ jav√≠t√°sa"""
        selector = fix_config['selector']
        keep_file = fix_config['keep_file']
        remove_from = fix_config['remove_from']
        
        print(f"  üîß Jav√≠t√°s: {selector}")
        print(f"     ‚úÖ Megtartva: {keep_file}")
        
        for file_to_clean in remove_from:
            file_path = Path(file_to_clean)
            if not file_path.exists():
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Szelektort tartalmaz√≥ blokk elt√°vol√≠t√°sa
                cleaned_content = self._remove_css_block(content, selector)
                
                if cleaned_content != content:
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(cleaned_content)
                    print(f"     üóëÔ∏è  Elt√°vol√≠tva: {file_to_clean}")
                
            except Exception as e:
                print(f"     ‚ùå Hiba: {file_to_clean} - {e}")
    
    def _remove_css_block(self, content, selector):
        """CSS blokk elt√°vol√≠t√°sa szelektora alapj√°n"""
        lines = content.split('\n')
        result_lines = []
        skip_block = False
        brace_count = 0
        
        for line in lines:
            stripped = line.strip()
            
            # Szelektort tartalmaz√≥ sor keres√©se
            if selector in stripped and '{' in stripped:
                skip_block = True
                brace_count = stripped.count('{') - stripped.count('}')
                continue
            
            if skip_block:
                brace_count += stripped.count('{') - stripped.count('}')
                if brace_count <= 0:
                    skip_block = False
                continue
            
            result_lines.append(line)
        
        return '\n'.join(result_lines)
    
    def fix_utility_class_duplications(self):
        """Utility class duplik√°ci√≥k jav√≠t√°sa - PRIORIT√ÅS 2"""
        print("\nüü° PRIORIT√ÅS 2: Utility class duplik√°ci√≥k jav√≠t√°sa")
        
        # Utility classok k√∂zpontos√≠t√°sa
        utility_fixes = [
            {
                'pattern': r'\.text-\w+',
                'target_file': '02-shared/utilities.css'
            },
            {
                'pattern': r'\.bg-\w+',
                'target_file': '02-shared/utilities.css'
            },
            {
                'pattern': r'\.border-\w+',
                'target_file': '02-shared/utilities.css'
            }
        ]
        
        for fix in utility_fixes:
            self._consolidate_utility_classes(fix)
    
    def _consolidate_utility_classes(self, fix_config):
        """Utility classok konszolid√°l√°sa"""
        pattern = fix_config['pattern']
        target_file = fix_config['target_file']
        
        print(f"  üîß Utility konszolid√°l√°s: {pattern} ‚Üí {target_file}")
        
        # Implement√°ci√≥ k√©s≈ëbb...
        pass
    
    def fix_within_file_duplications(self):
        """Within-file duplik√°ci√≥k jav√≠t√°sa - PRIORIT√ÅS 3"""
        print("\nüü¢ PRIORIT√ÅS 3: Within-file duplik√°ci√≥k jav√≠t√°sa")
        
        css_files = list(Path(".").rglob("*.css"))
        
        for css_file in css_files:
            if css_file.name in ["main_combined_financehub.css", "main_financehub.css"]:
                continue
            
            self._fix_within_file_duplications(css_file)
    
    def _fix_within_file_duplications(self, css_file):
        """Egy f√°jlon bel√ºli duplik√°ci√≥k jav√≠t√°sa"""
        try:
            with open(css_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Duplik√°lt szelektorok keres√©se √©s elt√°vol√≠t√°sa
            cleaned_content = self._remove_duplicate_selectors_in_file(content)
            
            if cleaned_content != content:
                with open(css_file, 'w', encoding='utf-8') as f:
                    f.write(cleaned_content)
                print(f"  üîß Jav√≠tva: {css_file}")
        
        except Exception as e:
            print(f"  ‚ùå Hiba: {css_file} - {e}")
    
    def _remove_duplicate_selectors_in_file(self, content):
        """Duplik√°lt szelektorok intelligens egyes√≠t√©se egy f√°jlon bel√ºl.

        A r√©gebbi implement√°ci√≥ a duplik√°lt blokkokat egyszer≈±en eldobta ‚Äì ez vesz√©lyes,
        mert elveszhetnek stilus-deklar√°ci√≥k, vagy felborulhat a deklar√°ci√≥k sorrendje,
        amely befoly√°solja a CSS kaszk√°dot.  Az √∫j logika a k√∂vetkez≈ët teszi:

        1.  V√©gigiter√°l a legfels≈ë (root) szinten l√©v≈ë blokkokon, @-szab√°lyokon k√≠v√ºl.
        2.  Az adott szelektor √∂sszes deklar√°ci√≥j√°t **√∂sszeolvasztja** ‚Äì ha ugyanaz a
            property n√©v t√∂bbsz√∂r szerepel, a legutols√≥ √©rt√©k nyer (ez felel meg a
            term√©szetes CSS-kaszk√°dnak).
        3.  A v√©g√©n az els≈ë el≈ëfordul√°s hely√©n hagyja az √∂sszevont blokkot, az √∂sszes
            k√©s≈ëbbi duplik√°lt blokkot pedig elt√°vol√≠tja.

        A f√ºggv√©ny NEM √©rinti az @media, @keyframes stb. blokkokat, illetve a benn√ºk
        l√©v≈ë esetleges duplik√°ci√≥kat ‚Äì azok √°ltal√°ban kontextus-specifikusak.
        """
        import re
        from collections import OrderedDict

        # Gyors kil√©p√©s, ha nincs kapcsos z√°r√≥jel
        if '{' not in content:
            return content

        # Regex a root-szint≈± blokkok gyors kinyer√©s√©hez (nem @-rule, nincs be√°gyazott
        # kapcsos z√°r√≥jel).  Nem t√∂k√©letes parser, de a FinanceHub CSS f√°jlokn√°l
        # elegend≈ë ‚Äì a be√°gyazott @-rule-okat el≈ëtte kiv√°gjuk.
        block_regex = re.compile(r'(?:^[^{@][^{]*?)\{[^{}]*?\}', re.M | re.S)

        # Els≈ë k√∂r ‚Äì kigy≈±jtj√ºk a blokkokat poz√≠ci√≥val egy√ºtt
        blocks = []  # (start_idx, end_idx, selector_text, body_text)
        for m in block_regex.finditer(content):
            start, end = m.span()
            raw_block = m.group(0)
            selector_part, body_part = raw_block.split('{', 1)
            selector = selector_part.strip()
            body = body_part.rsplit('}', 1)[0]  # remove trailing }
            blocks.append((start, end, selector, body))

        if not blocks:
            return content  # semmi dolgunk

        # Map a szelektoronk√©nti √∂sszevont property-list√°khoz
        merged_props: dict[str, "OrderedDict[str, str]"] = {}
        first_occurrence_index: dict[str, int] = {}

        # Helper: property-sor feldolgoz√°sa ‚Üí (prop, value)
        def parse_property_line(line: str):
            if ':' not in line:
                return None, None
            prop, val = line.split(':', 1)
            return prop.strip(), val.strip().rstrip(';')

        for idx, (start, end, selector, body) in enumerate(blocks):
            # Egyszer≈± normaliz√°l√°s ‚Äì t√∂bbsz√∂r√∂s sz√≥k√∂z ‚Üí egy sz√≥k√∂z
            normalized_selector = re.sub(r'\s+', ' ', selector)
            if normalized_selector not in merged_props:
                merged_props[normalized_selector] = OrderedDict()
                first_occurrence_index[normalized_selector] = idx  # eredeti sorrend megtart√°sa

            # Feldolgozzuk a tulajdons√°gokat soronk√©nt
            for line in body.split('\n'):
                stripped = line.strip()
                if not stripped or stripped.startswith('/*'):
                    # Komment vagy √ºres sor ‚Üí tov√°bb√≠tjuk az eredeti blokkban, ha az
                    # els≈ë el≈ëfordul√°sban volt.  A kommentek sorrendje nem kritikus.
                    continue
                prop, val = parse_property_line(stripped)
                if prop:
                    # A k√©s≈ëbbi el≈ëfordul√°s fel√ºl√≠rja az √©rt√©ket (CSS cascade)
                    merged_props[normalized_selector][prop] = val

        # √öj blokk sz√∂veg√©nek √∂ssze√°ll√≠t√°sa szelektoronk√©nt
        rebuilt_blocks = {}
        for selector, props in merged_props.items():
            prop_lines = [f"  {p}: {v};" for p, v in props.items()]
            block_text = selector + " {\n" + "\n".join(prop_lines) + "\n}"
            rebuilt_blocks[selector] = block_text

        # M√°sodik k√∂r ‚Äì eredeti content √∫jra√©p√≠t√©se, duplik√°tumok kisz≈±r√©se
        new_content_parts = []
        last_idx = 0
        processed_selectors = set()

        for start, end, selector, _ in blocks:
            normalized_selector = re.sub(r'\s+', ' ', selector)
            # Add content between previous block end and this block start (kommentek, @-rule-ok stb.)
            new_content_parts.append(content[last_idx:start])

            if normalized_selector in processed_selectors:
                # Ezt a duplik√°lt blokkot kihagyjuk
                pass  # semmit sem adunk hozz√°
            else:
                # Els≈ë (√©s egyetlen) el≈ëfordul√°s ‚Üí beillesztj√ºk az √∂sszevont verzi√≥t
                new_content_parts.append(rebuilt_blocks[normalized_selector])
                processed_selectors.add(normalized_selector)
            last_idx = end  # tov√°bb l√©p√ºnk

        # A marad√©k tartalom (f√°jl v√©ge) hozz√°f≈±z√©se
        new_content_parts.append(content[last_idx:])

        cleaned_css = "".join(new_content_parts)
        return cleaned_css
    
    def run_cleanup_cycle(self):
        """Egy teljes cleanup ciklus futtat√°sa"""
        print("üöÄ SZISZTEMATIKUS CLEANUP IND√çT√ÅSA")
        print("=" * 60)
        
        # Kezdeti √°llapot
        initial_count = self.get_current_benchmark()
        print(f"üìä Kezdeti duplik√°ci√≥k: {initial_count}")
        
        if initial_count == 0:
            print("üéâ Nincs t√∂bb duplik√°ci√≥!")
            return
        
        # Biztons√°gi ment√©s
        self.create_backup()
        
        # Priorit√°s szerinti jav√≠t√°s
        self.fix_cross_file_duplications()
        
        # Benchmark friss√≠t√©se
        current_count = self.regenerate_benchmark()
        print(f"\nüìà PROGRESS: {initial_count} ‚Üí {current_count} duplik√°ci√≥")
        
        if current_count < initial_count:
            print(f"‚úÖ Jav√≠tva: {initial_count - current_count} duplik√°ci√≥!")
        else:
            print("‚ö†Ô∏è  Nincs javul√°s, k√∂vetkez≈ë priorit√°s...")
        
        # Folytat√°s ha m√©g vannak duplik√°ci√≥k
        if current_count > 0:
            self.fix_utility_class_duplications()
            current_count = self.regenerate_benchmark()
            print(f"üìà PROGRESS: {initial_count} ‚Üí {current_count} duplik√°ci√≥")
        
        if current_count > 0:
            self.fix_within_file_duplications()
            current_count = self.regenerate_benchmark()
            print(f"üìà FINAL PROGRESS: {initial_count} ‚Üí {current_count} duplik√°ci√≥")
        
        # V√©gs≈ë eredm√©ny
        print(f"\nüéØ CLEANUP CIKLUS BEFEJEZVE")
        print(f"üìä V√©gs≈ë duplik√°ci√≥k: {current_count}")
        
        if current_count == 0:
            print("üéâ MINDEN DUPLIK√ÅCI√ì JAV√çTVA!")
        else:
            print(f"üîÑ K√∂vetkez≈ë ciklusban folytatjuk...")

def main():
    """F≈ë cleanup folyamat"""
    cleaner = DuplicationCleaner()
    cleaner.run_cleanup_cycle()

if __name__ == "__main__":
    main() 