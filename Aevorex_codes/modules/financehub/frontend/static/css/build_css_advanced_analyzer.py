#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
===============================================================
AEVOREX FINANCEHUB CSS SOURCE DUPLIK√ÅCI√ì ANAL√çZIS
SMART DUPLIK√ÅCI√ì DETEKT√ÅL√ÅS - Media Query Aware
SOURCE F√ÅJLOK (modulok) duplik√°ci√≥ elemz√©se - NEM a combined output!
===============================================================
"""

import re
import sys
import os
from pathlib import Path
from collections import defaultdict, Counter
import json

class CSSContext:
    """CSS kontextus tracker - media query, keyframes, stb."""
    def __init__(self):
        self.media_queries = []
        self.keyframes = []
        self.nesting_level = 0
        
    def __str__(self):
        if self.media_queries:
            return f"@media({', '.join(self.media_queries)})"
        elif self.keyframes:
            return f"@keyframes({', '.join(self.keyframes)})"
        else:
            return "global"
    
    def copy(self):
        """Create a copy of the context"""
        new_ctx = CSSContext()
        new_ctx.media_queries = self.media_queries.copy()
        new_ctx.keyframes = self.keyframes.copy()
        new_ctx.nesting_level = self.nesting_level
        return new_ctx

def extract_media_query(line):
    """Extract media query condition from @media line"""
    match = re.search(r'@media\s+(.+?)\s*{', line)
    if match:
        return match.group(1).strip()
    return "unknown"

def extract_keyframe_name(line):
    """Extract keyframe name from @keyframes line"""
    match = re.search(r'@keyframes\s+(\w+)', line)
    if match:
        return match.group(1)
    return "unknown"

def parse_css_with_context(content):
    """
    Parse CSS f√°jl kontextussal (media queries, keyframes, stb.)
    
    Returns:
        List of (selector, line_num, context, full_line)
    """
    lines = content.split('\n')
    results = []
    context_stack = [CSSContext()]  # Stack for nested contexts
    
    for line_num, line in enumerate(lines, 1):
        original_line = line
        line = line.strip()
        
        if not line or line.startswith('/*'):
            continue
            
        current_context = context_stack[-1]
        
        # === CONTEXT TRACKING ===
        
        # Media query start
        if line.startswith('@media'):
            media_query = extract_media_query(line)
            new_context = current_context.copy()
            new_context.media_queries.append(media_query)
            new_context.nesting_level += 1
            context_stack.append(new_context)
            continue
            
        # Keyframes start  
        elif line.startswith('@keyframes'):
            keyframe_name = extract_keyframe_name(line)
            new_context = current_context.copy()
            new_context.keyframes.append(keyframe_name)
            new_context.nesting_level += 1
            context_stack.append(new_context)
            continue
            
        # Other @ rules (skip)
        elif line.startswith('@'):
            continue
            
        # Block end - reduce context
        elif line == '}' and len(context_stack) > 1:
            context_stack.pop()
            continue
            
        # CSS Selector
        elif '{' in line:
            selector = line.split('{')[0].strip()
            if selector:
                # Normalize selector
                normalized_selector = re.sub(r'\s+', ' ', selector.strip())
                
                # KEYFRAMES CONTEXT - csak akkor add hozz√°, ha nem keyframes szelektorr√≥l van sz√≥
                if current_context.keyframes:
                    # Keyframes szelektorok: 0%, 50%, 100%, from, to
                    if re.match(r'^\d+%$', normalized_selector) or normalized_selector in ['from', 'to']:
                        # Ezeket k√ºl√∂n kezelj√ºk - NEM duplik√°ci√≥k!
                        continue
                
                # Skip pseudo-element-only selectors (::before, ::after)
                if not normalized_selector.startswith('::'):
                    results.append((
                        normalized_selector,
                        line_num,
                        current_context.copy(),
                        original_line.strip()
                    ))
    
    return results

def is_responsive_override(selector_occurrences):
    """
    Meghat√°rozza, hogy a selector el≈ëfordul√°sok responsive overrides-ok vagy val√≥di duplik√°ci√≥k.
    
    Args:
        selector_occurrences: List of (file_path, line_num, context, full_line)
    
    Returns:
        (is_responsive, explanation)
    """
    contexts = [str(occ[2]) for occ in selector_occurrences]
    
    # KEYFRAMES SELECTORS - ezek MINDIG validak (0%, 50%, 100%, stb.)
    selector = selector_occurrences[0][0] if selector_occurrences else ""
    if re.match(r'^\d+%$', selector.strip()) or selector.strip() in ['from', 'to']:
        return True, "Keyframes selector (0%, 50%, 100%, from, to) - mindig valid"
    
    # Ha minden el≈ëfordul√°s k√ºl√∂nb√∂z≈ë kontextusban van -> responsive
    unique_contexts = set(contexts)
    if len(unique_contexts) == len(contexts):
        return True, "Minden el≈ëfordul√°s k√ºl√∂nb√∂z≈ë media query kontextusban"
    
    # Ha van global + media query mix -> responsive  
    has_global = any(ctx == "global" for ctx in contexts)
    has_media = any("@media" in ctx for ctx in contexts)
    
    if has_global and has_media:
        return True, "Base defin√≠ci√≥ + responsive overrides"
    
    # Ha csak media query-k, de mind k√ºl√∂nb√∂z≈ë -> responsive
    if all("@media" in ctx for ctx in contexts) and len(unique_contexts) == len(contexts):
        return True, "K√ºl√∂nb√∂z≈ë media query overrides"
    
    # UGYANAZON F√ÅJLON BEL√úLI RESPONSIVE OVERRIDES
    files_involved = [occ[0] for occ in selector_occurrences]
    if len(set(files_involved)) == 1:  # Csak egy f√°jlban
        # Ha van base + media query ugyanabban a f√°jlban -> responsive
        if has_global and has_media:
            return True, "Ugyanazon f√°jlban: base + responsive overrides"
        # Ha csak k√ºl√∂nb√∂z≈ë media query-k -> responsive
        if all("@media" in ctx for ctx in contexts) and len(unique_contexts) > 1:
            return True, "Ugyanazon f√°jlban: k√ºl√∂nb√∂z≈ë responsive breakpoint-ok"
    
    # CROSS-FILE ANALYSIS - csak akkor duplik√°ci√≥, ha UGYANABBAN A KONTEXTUSBAN
    if len(set(files_involved)) > 1:  # T√∂bb f√°jlban
        # Ha minden global kontextusban -> val√≥di duplik√°ci√≥
        if all(ctx == "global" for ctx in contexts):
            return False, "T√∂bb f√°jlban, global kontextusban - val√≥di duplik√°ci√≥"
        # Ha van media query mix -> lehet responsive
        if has_media:
            return True, "T√∂bb f√°jlban, de media query kontextusban - responsive override"
    
    # Egy√©bk√©nt val√≥di duplik√°ci√≥
    return False, "Azonos kontextusban t√∂bbsz√∂r defini√°lva"

class SourceCSSAnalyzer:
    def __init__(self, css_directory):
        self.css_dir = Path(css_directory)
        self.files_data = {}
        self.all_selector_data = defaultdict(list)  # {selector: [occurrences]}
        self.real_duplicates = []
        self.responsive_overrides = []
        
        # SOURCE F√ÅJLOK - kiz√°rjuk a build outputokat
        self.excluded_files = {
            'main_combined_financehub.css',  # BUILD OUTPUT
            'css_duplication_analysis.json',  # ANAL√çZIS OUTPUT
        }
        
    def scan_css_files(self):
        """SOURCE CSS f√°jlok szkennel√©se - BUILD OUTPUTOK N√âLK√úL."""
        print(f"üîç SOURCE CSS modulok szkennel√©se: {self.css_dir}")
        
        css_files = []
        for css_file in self.css_dir.rglob("*.css"):
            if css_file.name not in self.excluded_files:
                css_files.append(css_file)
        
        print(f"üìÇ Tal√°lt SOURCE CSS f√°jlok: {len(css_files)}")
        print(f"üö´ Kiz√°rt build outputok: {', '.join(self.excluded_files)}")
        
        for css_file in css_files:
            self.analyze_file(css_file)
        
        return len(css_files)
    
    def analyze_file(self, css_file):
        """Egy SOURCE CSS f√°jl elemz√©se SMART CONTEXT PARSING-gel."""
        try:
            with open(css_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # SKIP @import f√°jlokat - ezek csak import√°lnak
            if self.is_import_only_file(content):
                print(f"‚è≠Ô∏è  √Åtugrom (import-only): {css_file.name}")
                return
            
            rel_path = css_file.relative_to(self.css_dir)
            file_key = str(rel_path)
            
            # F√°jl adatok t√°rol√°sa
            self.files_data[file_key] = {
                'path': css_file,
                'size': len(content),
                'lines': content.count('\n') + 1,
                'module': self.get_module_category(rel_path)
            }
            
            # SMART CONTEXT PARSING
            selectors = parse_css_with_context(content)
            
            # Glob√°lis szelektor t√©rk√©p friss√≠t√©se
            for selector, line_num, context, full_line in selectors:
                self.all_selector_data[selector].append((file_key, line_num, context, full_line))
            
            print(f"‚úÖ Elemezve: {rel_path} ({len(selectors)} szelektor)")
            
        except Exception as e:
            print(f"‚ùå Hiba {css_file} elemz√©sekor: {e}")
    
    def is_import_only_file(self, content):
        """Ellen≈ërzi hogy egy f√°jl csak @import utas√≠t√°sokat tartalmaz-e."""
        lines = [line.strip() for line in content.split('\n') 
                if line.strip() and not line.strip().startswith('/*')]
        
        if len(lines) == 0:
            return True
            
        import_lines = [line for line in lines if line.startswith('@import')]
        non_import_lines = [line for line in lines if not line.startswith('@import') and line != '']
        
        # Ha az √∂sszes √©rdemi sor @import, akkor ez egy import-only f√°jl
        return len(non_import_lines) <= 2  # Max 2 sor (pl. comments)
    
    def get_module_category(self, rel_path):
        """Modul kateg√≥ria meghat√°roz√°sa a f√°jl √∫tvonala alapj√°n."""
        path_str = str(rel_path)
        
        if path_str.startswith('01-base/'):
            return 'base'
        elif path_str.startswith('02-shared/'):
            return 'shared'
        elif path_str.startswith('03-layout/'):
            return 'layout'
        elif path_str.startswith('04-components/'):
            component = path_str.split('/')[1] if '/' in path_str else 'general'
            return f'component-{component}'
        elif path_str.startswith('05-themes/'):
            return 'theme'
        elif path_str.startswith('06-pages/'):
            return 'page'
        elif path_str.startswith('07-vendor/'):
            return 'vendor'
        else:
            return 'other'
    
    def analyze_duplicates(self):
        """SMART duplik√°ci√≥ elemz√©s - media query aware."""
        print("\nüß† === SMART DUPLIK√ÅCI√ì ELEMZ√âS ===")
        
        for selector, occurrences in self.all_selector_data.items():
            if len(occurrences) > 1:
                is_responsive, explanation = is_responsive_override(occurrences)
                
                if is_responsive:
                    self.responsive_overrides.append((selector, occurrences, explanation))
                else:
                    self.real_duplicates.append((selector, occurrences, explanation))
        
        print(f"‚úÖ Elemz√©s k√©sz:")
        print(f"   üîß Val√≥di duplik√°ci√≥k: {len(self.real_duplicates)}")
        print(f"   üì± Responsive overrides: {len(self.responsive_overrides)}")
        
        return len(self.real_duplicates), len(self.responsive_overrides)

    def generate_detailed_report(self):
        """R√©szletes duplik√°ci√≥ jelent√©s gener√°l√°sa."""
        print("\n" + "="*80)
        print("üìã SOURCE CSS MODULOK DUPLIK√ÅCI√ì JELENT√âS")
        print("="*80)
        
        # √ñsszegz√©s
        total_real = len(self.real_duplicates)
        total_responsive = len(self.responsive_overrides)
        
        print(f"\nüìä √ñSSZEGZ√âS:")
        print(f"   ‚Ä¢ SOURCE f√°jlok elemezve: {len(self.files_data)}")
        print(f"   ‚Ä¢ Val√≥di duplik√°ci√≥k: {total_real}")
        print(f"   ‚Ä¢ Responsive overrides: {total_responsive}")
        print(f"   ‚Ä¢ √ñsszes duplik√°ci√≥: {total_real + total_responsive}")
        
        # MODUL SZINT≈∞ BREAKDOWN
        print(f"\nüìÇ MODUL SZINT≈∞ BREAKDOWN:")
        module_stats = defaultdict(lambda: {'files': 0, 'real_dups': 0, 'responsive_dups': 0})
        
        # Modul statisztik√°k √∂sszegy≈±jt√©se
        for file_key, file_data in self.files_data.items():
            module = file_data['module']
            module_stats[module]['files'] += 1
        
        # Real duplik√°ci√≥k hozz√°ad√°sa
        for selector, occurrences, explanation in self.real_duplicates:
            files_involved = set(occ[0] for occ in occurrences)
            for file_key in files_involved:
                if file_key in self.files_data:
                    module = self.files_data[file_key]['module']
                    module_stats[module]['real_dups'] += 1
        
        # Responsive overrides hozz√°ad√°sa
        for selector, occurrences, explanation in self.responsive_overrides:
            files_involved = set(occ[0] for occ in occurrences)
            for file_key in files_involved:
                if file_key in self.files_data:
                    module = self.files_data[file_key]['module']
                    module_stats[module]['responsive_dups'] += 1
        
        # Modulok megjelen√≠t√©se
        for module, stats in sorted(module_stats.items()):
            total_module_dups = stats['real_dups'] + stats['responsive_dups']
            if total_module_dups > 0:
                print(f"\n   üì¶ {module.upper()}:")
                print(f"      ‚Ä¢ {stats['files']} f√°jl")
                print(f"      ‚Ä¢ {stats['real_dups']} val√≥di duplik√°ci√≥")
                print(f"      ‚Ä¢ {stats['responsive_dups']} responsive override")
                print(f"      ‚Ä¢ √ñSSZESEN: {total_module_dups} probl√©ma")
        
        # KRITIKUS F√ÅJLOK LIST√ÅJA
        print(f"\nüî• KRITIKUS F√ÅJLOK (legt√∂bb duplik√°ci√≥val):")
        file_dup_count = defaultdict(int)
        
        # Count real duplicates per file
        for selector, occurrences, explanation in self.real_duplicates:
            for file_key, line_num, context, full_line in occurrences:
                file_dup_count[file_key] += 1
        
        # Sort by duplication count
        file_priorities = [(file_key, count, self.files_data[file_key]['module']) 
                          for file_key, count in file_dup_count.items() if count > 0]
        file_priorities.sort(key=lambda x: x[1], reverse=True)
        
        for file_key, dup_count, module in file_priorities[:10]:
            print(f"   üî¥ {file_key} [{module}]: {dup_count} duplik√°ci√≥")
        
        # KOMPONENS SZINT≈∞ KERESZT-DUPLIK√ÅCI√ìK
        print(f"\nüîÑ KOMPONENS SZINT≈∞ KERESZT-DUPLIK√ÅCI√ìK:")
        component_cross = defaultdict(list)
        
        for selector, occurrences, explanation in self.responsive_overrides:
            # Komponens t√≠pusok azonos√≠t√°sa
            modules = [self.files_data[occ[0]]['module'] for occ in occurrences if occ[0] in self.files_data]
            
            if any(m.startswith('component-') for m in modules):
                component_type = 'components'
            elif any('layout' in m for m in modules):
                component_type = 'layout'
            elif any('shared' in m for m in modules):
                component_type = 'shared'
            else:
                component_type = 'mixed'
                
            component_cross[component_type].append((selector, occurrences))
        
        for comp_type, selectors in component_cross.items():
            if selectors:
                print(f"\n   üìÇ {comp_type.upper()} kereszt-duplik√°ci√≥k:")
                for selector, occurrences in selectors[:5]:
                    files = set(occ[0] for occ in occurrences)
                    print(f"      ‚Ä¢ {selector} ‚Üí {', '.join(files)}")
                if len(selectors) > 5:
                    print(f"      ... √©s m√©g {len(selectors) - 5} duplik√°ci√≥")
        
        return {
            'real_total': total_real,
            'responsive_total': total_responsive,
            'total': total_real + total_responsive,
            'module_stats': dict(module_stats)
        }
    
    def generate_target_list(self):
        """MODUL√ÅRIS TISZT√çT√ÅSI PRIORIT√ÅSI LISTA gener√°l√°sa."""
        print(f"\nüéØ MODUL√ÅRIS TISZT√çT√ÅSI PRIORIT√ÅSI LISTA:")
        
        # 1. KRITIKUS MODULOK - val√≥di duplik√°ci√≥k alapj√°n
        module_priorities = defaultdict(lambda: {'real_dups': 0, 'files': [], 'total_impact': 0})
        
        # Count real duplicates per module
        for selector, occurrences, explanation in self.real_duplicates:
            files_involved = set(occ[0] for occ in occurrences)
            for file_key in files_involved:
                if file_key in self.files_data:
                    module = self.files_data[file_key]['module']
                    module_priorities[module]['real_dups'] += 1
                    module_priorities[module]['total_impact'] += 1
                    if file_key not in [f[0] for f in module_priorities[module]['files']]:
                        module_priorities[module]['files'].append((file_key, 1))
        
        # Rendez√©s impact szerint
        sorted_modules = sorted(module_priorities.items(), 
                              key=lambda x: x[1]['total_impact'], reverse=True)
        
        print(f"\n1Ô∏è‚É£ PRIORIT√ÅS 1 - MODULON BEL√úLI DUPLIK√ÅCI√ìK:")
        for module, data in sorted_modules[:5]:
            if data['real_dups'] > 0:
                print(f"\n   üì¶ {module.upper()} modul ({data['real_dups']} duplik√°ci√≥):")
                for file_key, dup_count in data['files'][:3]:
                    print(f"      üîß {file_key}: duplik√°ci√≥k tal√°lhat√≥k")
                    
                    # Konkr√©t javaslatok
                    if 'component-analysis-bubbles' in module:
                        print(f"         ‚Üí Konszolid√°ld a .bubble-* oszt√°lyokat!")
                        print(f"         ‚Üí Mozgasd √°t a k√∂z√∂s st√≠lusokat bubble-base.css-be!")
                    elif 'component-chart' in module:
                        print(f"         ‚Üí Egyes√≠tsd a media query-ket!")
                        print(f"         ‚Üí Refaktor√°ld chart-base.css + chart-responsive.css-re!")
                    elif 'layout' in module:
                        print(f"         ‚Üí Grid √©s flexbox duplik√°ci√≥k tiszt√≠t√°sa!")
                    elif 'shared' in module:
                        print(f"         ‚Üí Utility oszt√°lyok deduplik√°l√°sa!")
        
        # 2. KOMPONENS KERESZT-DUPLIK√ÅCI√ìK
        print(f"\n2Ô∏è‚É£ PRIORIT√ÅS 2 - KOMPONENS KERESZT-DUPLIK√ÅCI√ìK:")
        
        cross_component_issues = []
        for selector, occurrences, explanation in self.responsive_overrides:
            files_involved = [occ[0] for occ in occurrences]
            modules = [self.files_data[f]['module'] for f in files_involved if f in self.files_data]
            if len(set(modules)) > 1:  # T√∂bb modulban is szerepel
                cross_component_issues.append((selector, modules, len(occurrences)))
        
        # Leggyakoribb kereszt-duplik√°ci√≥k
        cross_component_issues.sort(key=lambda x: x[2], reverse=True)
        
        for selector, modules, count in cross_component_issues[:8]:
            unique_modules = list(set(modules))
            print(f"   üîÑ `{selector}` ({count}x) ‚Üí {', '.join(unique_modules)}")
            
            # Modulspecifikus javaslatok
            if 'shared' in unique_modules and any('component-' in m for m in unique_modules):
                print(f"      üí° Mozgasd √°t 02-shared/utilities.css-be!")
            elif len([m for m in unique_modules if m.startswith('component-')]) > 1:
                print(f"      üí° L√©trehozd az 04-components/shared/ mapp√°t!")
        
        # 3. AZONNALI AKCI√ìK
        print(f"\n3Ô∏è‚É£ AZONNALI AKCI√ìK:")
        print(f"   üîß 1. Kezdd a legnagyobb impact modulokkal")
        print(f"   üîß 2. Konszolid√°ld a .utility oszt√°lyokat 02-shared/utilities.css-be")
        print(f"   üîß 3. Hozd l√©tre 04-components/shared/ mapp√°t k√∂z√∂s komponens st√≠lusoknak")
        print(f"   üîß 4. Refaktor√°ld a chart komponenst: base + responsive f√°jlokra")
        print(f"   üîß 5. Analysis bubbles: k√∂z√∂s bubble-base.css l√©trehoz√°sa")

    def save_detailed_json(self, output_file="css_duplication_analysis.json"):
        """R√©szletes anal√≠zis ment√©se JSON form√°tumban."""
        
        # Convert tuples to serializable format
        real_duplicates_data = []
        for selector, occurrences, explanation in self.real_duplicates:
            real_duplicates_data.append({
                'selector': selector,
                'explanation': explanation,
                'occurrences': [
                    {
                        'file': occ[0],
                        'line': occ[1],
                        'context': str(occ[2]),
                        'full_line': occ[3]
                    } for occ in occurrences
                ]
            })
        
        responsive_overrides_data = []
        for selector, occurrences, explanation in self.responsive_overrides:
            responsive_overrides_data.append({
                'selector': selector,
                'explanation': explanation,
                'occurrences': [
                    {
                        'file': occ[0],
                        'line': occ[1],
                        'context': str(occ[2]),
                        'full_line': occ[3]
                    } for occ in occurrences
                ]
            })
        
        analysis_data = {
            'timestamp': str(Path().cwd()),
            'files_analyzed': len(self.files_data),
            'real_duplicates': real_duplicates_data,
            'responsive_overrides': responsive_overrides_data,
            'files_data': self.files_data
        }
        
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(analysis_data, f, indent=2, ensure_ascii=False)
            print(f"üíæ R√©szletes anal√≠zis mentve: {output_file}")
        except Exception as e:
            print(f"‚ùå JSON ment√©si hiba: {e}")

    def list_real_duplicates_for_cleanup(self):
        """
        VAL√ìDI DUPLIK√ÅCI√ìK R√âSZLETES LIST√ÅZ√ÅSA TISZT√çT√ÅSI C√âLOKRA
        """
        print(f"\nüßπ === VAL√ìDI DUPLIK√ÅCI√ìK TISZT√çT√ÅSI LIST√ÅJA ===")
        print(f"√ñsszesen {len(self.real_duplicates)} val√≥di duplik√°ci√≥ tal√°lhat√≥:")
        
        # Rendez√©s s√∫lyoss√°g szerint (el≈ëfordul√°sok sz√°ma)
        sorted_real_dups = sorted(self.real_duplicates, 
                                 key=lambda x: len(x[1]), reverse=True)
        
        for i, (selector, occurrences, explanation) in enumerate(sorted_real_dups, 1):
            print(f"\n{i:2d}. üî¥ `{selector}` ({len(occurrences)} el≈ëfordul√°s)")
            print(f"    üí° {explanation}")
            
            # F√°jlok √©s kontextusok list√°z√°sa
            for file_path, line_num, context, full_line in occurrences:
                module = self.files_data.get(file_path, {}).get('module', 'unknown')
                context_str = str(context)
                if context_str == "global":
                    context_display = "üåê global"
                elif "@media" in context_str:
                    context_display = f"üì± {context_str}"
                else:
                    context_display = f"üîß {context_str}"
                    
                print(f"       üìÅ {file_path}:{line_num} [{module}] {context_display}")
                print(f"          ‚îî‚îÄ {full_line[:80]}{'...' if len(full_line) > 80 else ''}")
            
            # Tiszt√≠t√°si javaslat
            files_involved = list(set(occ[0] for occ in occurrences))
            modules_involved = list(set(self.files_data.get(f, {}).get('module', 'unknown') for f in files_involved))
            
            if len(files_involved) == 1:
                print(f"    üîß JAVASLAT: Ugyanazon f√°jlban duplik√°lt - egyes√≠tsd a defin√≠ci√≥kat!")
            elif len(modules_involved) == 1:
                print(f"    üîß JAVASLAT: Ugyanazon modulban - konszolid√°ld egy f√°jlba!")
            elif 'shared' in modules_involved:
                print(f"    üîß JAVASLAT: Mozgasd √°t a shared modulba: 02-shared/utilities.css")
            elif any('component-' in m for m in modules_involved):
                print(f"    üîß JAVASLAT: Hozz l√©tre 04-components/shared/ mapp√°t!")
            else:
                print(f"    üîß JAVASLAT: V√°laszd ki a legmegfelel≈ëbb helyet √©s t√∂r√∂ld a t√∂bbit!")
        
        # √ñSSZEGZ√âS MODULONK√âNT
        print(f"\nüìä === MODULONK√âNTI √ñSSZEGZ√âS ===")
        module_dup_count = defaultdict(int)
        
        for selector, occurrences, explanation in self.real_duplicates:
            files_involved = [occ[0] for occ in occurrences]
            modules_involved = [self.files_data.get(f, {}).get('module', 'unknown') for f in files_involved]
            for module in set(modules_involved):
                module_dup_count[module] += 1
        
        sorted_modules = sorted(module_dup_count.items(), key=lambda x: x[1], reverse=True)
        
        for module, count in sorted_modules:
            print(f"   üì¶ {module}: {count} duplik√°ci√≥")
        
        return len(self.real_duplicates)

def main():
    css_dir = "."  # Jelenlegi mappa alap√©rtelmezett
    
    if len(sys.argv) > 1:
        css_dir = sys.argv[1]
    
    if not Path(css_dir).exists():
        print(f"‚ùå HIBA: A megadott mappa nem tal√°lhat√≥: {css_dir}")
        sys.exit(1)
    
    print("üöÄ AEVOREX CSS FEJLETT ANAL√çZIS")
    print("="*50)
    
    # Anal√≠zis futtat√°sa
    analyzer = SourceCSSAnalyzer(css_dir)
    
    files_count = analyzer.scan_css_files()
    if files_count == 0:
        print("‚ùå Nincsenek CSS f√°jlok a megadott mapp√°ban.")
        sys.exit(1)
    
    internal_count, responsive_count = analyzer.analyze_duplicates()
    
    # Jelent√©sek
    results = analyzer.generate_detailed_report()
    analyzer.generate_target_list()
    
    # JSON ment√©s automatikusan
    analyzer.save_detailed_json()
    
    # Tiszt√≠t√°si lista gener√°l√°sa
    analyzer.list_real_duplicates_for_cleanup()
    
    print(f"\nüéâ ANAL√çZIS BEFEJEZVE")
    print(f"√ñsszesen {results['total']} duplik√°ci√≥ azonos√≠tva")

if __name__ == "__main__":
    main() 