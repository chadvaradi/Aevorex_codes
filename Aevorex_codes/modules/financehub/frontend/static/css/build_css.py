#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
===============================================================
AEVOREX FINANCEHUB CSS BUNDLE BUILDER
Pr√©mium modulariz√°lt CSS build rendszer
Duplik√°ci√≥Detekt√°l√≥: list√°zza a probl√©m√°kat, nem rejti el
===============================================================
"""

import os
import re
import sys
from pathlib import Path
from datetime import datetime
from collections import defaultdict
import html
import html.parser as _htmlparser
import textwrap

# === KONFIGUR√ÅCI√ìS KONSTANSOK ===
CSS_BASE_DIR = Path(".")  # Current directory
OUTPUT_FILE = Path("main_combined_financehub.css")
DEV_MASTER_FILE = Path("main_financehub.css")

# === WHITELIST & BLACKLIST BE√ÅLL√çT√ÅSOK ===
#   A) Whitelist ‚Äì kiz√°r√≥lag ezekb√µl a k√∂nyvt√°rakb√≥l engedj√ºk be a CSS-f√°jlokat
#   B) Blacklist ‚Äì minden, ami backup / temp / archive stb. ‚Üí KIHAGYVA
WHITELIST_PREFIXES = [
    "01-base/", "02-shared/", "03-layout/", "04-components/",
    "05-themes/", "06-pages/", "07-vendor/"
]

# Regex-mint√°k a kiz√°r√°shoz (kis- √©s nagybet√ª √©rz√©ketlen)
BLACKLIST_REGEXES = [
    r"backup", r"temp", r"archive", r"duplicate", r"_old", r"google-cloud-sdk",
    r"node_modules", r"venv"
]

# === DUPLIK√ÅCI√ì DETEKT√ÅL√ÅS ===
def detect_duplicates_in_css_files():
    """CSS duplik√°ci√≥k detekt√°l√°sa √©s r√©szletes list√°z√°sa minden build el≈ëtt."""
    print("\nüîç === DUPLIK√ÅCI√ì DETEKT√ÅL√ÅS ===")
    print("A build script NEM fogja automatikusan jav√≠tani a duplik√°ci√≥kat!")
    print("Minden probl√©m√°t LIST√ÅZ, hogy manu√°lisan meg tudd oldani.\n")
    
    base_dir = Path(".")
    selector_locations = defaultdict(list)  # {selector: [(file_path, line_num), ...]}
    file_internal_duplicates = defaultdict(list)  # {file_path: [duplicated_selectors]}
    total_duplicates = 0
    
    # Minden CSS f√°jl vizsg√°lata
    for css_file in base_dir.rglob("*.css"):
        if css_file.name in ["main_combined_financehub.css", "main_financehub.css"]:
            continue
            
        try:
            with open(css_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # CSS szelektorok keres√©se
            lines = content.split('\n')
            file_selectors = defaultdict(list)  # Track selectors within this file
            
            for line_num, line in enumerate(lines, 1):
                line = line.strip()
                if '{' in line and not line.startswith('/*') and not line.startswith('@'):
                    # Szelektor kinyer√©se
                    selector = line.split('{')[0].strip()
                    if selector:
                        # Normaliz√°l√°s √∂sszehasonl√≠t√°shoz
                        normalized = re.sub(r'\s+', ' ', selector.strip())
                        rel_path = css_file.relative_to(base_dir)
                        
                        # Global tracking
                        selector_locations[normalized].append((str(rel_path), line_num))
                        
                        # File internal tracking
                        file_selectors[normalized].append(line_num)
            
            # Check for internal duplicates within the file
            for selector, line_nums in file_selectors.items():
                if len(line_nums) > 1:
                    file_internal_duplicates[str(css_file.relative_to(base_dir))].append({
                        'selector': selector,
                        'lines': line_nums,
                        'count': len(line_nums)
                    })
        
        except Exception as e:
            print(f"‚ö†Ô∏è  Hiba a f√°jl olvas√°sakor: {css_file} - {e}")
    
    # === KATEG√ìRI√ÅNK√âNTI ELEMZ√âS ===
    print("üìã === DUPLIK√ÅCI√ì KATEG√ìRI√ÅK ===\n")
    
    # 1. FILE INTERNAL DUPLICATES (bels≈ë duplik√°ci√≥k)
    print("üî• 1. F√ÅJLON BEL√úLI DUPLIK√ÅCI√ìK:")
    internal_total = 0
    for file_path, duplicates in file_internal_duplicates.items():
        if duplicates:
            print(f"\nüìÅ F√°jl: {file_path}")
            for dup in duplicates:
                internal_total += dup['count'] - 1  # -1 because the first occurrence is valid
                print(f"   üî¥ `{dup['selector']}` ‚Üí {dup['count']}√ó defini√°lva: sorok {', '.join(map(str, dup['lines']))}")
    
    if internal_total == 0:
        print("   ‚úÖ Nincs f√°jlon bel√ºli duplik√°ci√≥!")
    
    # 2. CROSS-FILE DUPLICATES (komponensek k√∂z√∂tti)
    print(f"\nüî• 2. KOMPONENSEK K√ñZ√ñTTI DUPLIK√ÅCI√ìK:")
    cross_file_total = 0
    component_groups = defaultdict(list)
    
    for selector, locations in selector_locations.items():
        if len(locations) > 1:
            # Group by component type
            files = [loc[0] for loc in locations]
            component_type = "mixed"
            
            if all("chart/" in f for f in files):
                component_type = "chart"
            elif all("analysis-bubbles/" in f for f in files):
                component_type = "analysis-bubbles"
            elif all("header/" in f for f in files):
                component_type = "header"
            elif all("stock-header/" in f for f in files):
                component_type = "stock-header"
            elif all("news/" in f for f in files):
                component_type = "news"
            
            component_groups[component_type].append((selector, locations))
            cross_file_total += 1
    
    for component_type, duplicates in component_groups.items():
        if duplicates:
            print(f"\n   üìÇ {component_type.upper()} komponens:")
            for selector, locations in duplicates[:5]:  # Show first 5 per category
                print(f"      üî¥ `{selector}` ‚Üí {len(locations)} helyen:")
                for file_path, line_num in locations:
                    print(f"         ‚Ü≥ {file_path}:{line_num}")
            if len(duplicates) > 5:
                print(f"      ... √©s m√©g {len(duplicates) - 5} duplik√°ci√≥")
    
    total_duplicates = internal_total + cross_file_total
    
    # === JAV√çT√ÅSI JAVASLATOK ===
    print(f"\nüí° === JAV√çT√ÅSI JAVASLATOK ===")
    
    if file_internal_duplicates:
        print("üõ†Ô∏è  PRIORIT√ÅS 1 - F√°jlon bel√ºli duplik√°ci√≥k:")
        for file_path, duplicates in list(file_internal_duplicates.items())[:3]:
            if duplicates:
                print(f"   üìù {file_path}:")
                print(f"      ‚Üí T√∂r√∂ld a duplik√°lt szelektorokat!")
                print(f"      ‚Üí Konszolid√°ld a CSS szab√°lyokat egy helyre!")
    
    if component_groups.get("chart"):
        print(f"\nüõ†Ô∏è  PRIORIT√ÅS 2 - Chart komponens tiszt√≠t√°sa:")
        print(f"      ‚Üí 04-components/chart/ almapp√°ban T√öLKOMPLEXIT√ÅS!")
        print(f"      ‚Üí V√°laszd sz√©t: chart-base.css + chart-responsive.css")
        print(f"      ‚Üí Konszolid√°ld a media query-ket!")
    
    if component_groups.get("analysis-bubbles"):
        print(f"\nüõ†Ô∏è  PRIORIT√ÅS 3 - Analysis bubbles refaktor:")
        print(f"      ‚Üí shared/bubbles-shared.css T√öLTERHELT!")
        print(f"      ‚Üí Mozgasd √°t a k√∂z√∂s st√≠lusokat bubble-base.css-be")
    
    # √ñsszefoglal√≥
    print(f"\nüìä === DUPLIK√ÅCI√ì √ñSSZEFOGLAL√ì ===")
    print(f"üîç Vizsg√°lt f√°jlok: {len(list(base_dir.rglob('*.css')))} CSS f√°jl")
    print(f"üî¥ Duplik√°lt szelektorok: {total_duplicates}")
    print(f"   ‚îî‚îÄ‚îÄ F√°jlon bel√ºli: {internal_total}")
    print(f"   ‚îî‚îÄ‚îÄ Komponensek k√∂z√∂tti: {cross_file_total}")
    print(f"üìÅ √ârintett f√°jlok: {len(set(loc[0] for locs in selector_locations.values() if len(locs) > 1 for loc in locs))}")
    
    if total_duplicates > 0:
        print(f"\n‚ö†Ô∏è  FIGYELEM: {total_duplicates} duplik√°lt szelektor tal√°lhat√≥!")
        print("üí° Javaslat: Priorit√°sok szerint tiszt√≠tsd meg a duplik√°ci√≥kat!")
        print("üõ†Ô∏è  1. F√°jlon bel√ºli duplik√°ci√≥k ‚Üí 2. Komponens refaktor ‚Üí 3. Cross-file cleanup")
        print()
    else:
        print("\n‚úÖ Nincs duplik√°ci√≥! A CSS strukt√∫ra tiszta.\n")
    
    return total_duplicates

def validate_file_structure():
    """CSS f√°jlstrukt√∫ra valid√°l√°sa √©s hi√°nyz√≥ f√°jlok jelz√©se."""
    print("üîç CSS f√°jlstrukt√∫ra valid√°l√°sa...")
    
    base_dir = Path(".")
    if not base_dir.exists():
        print(f"‚ùå HIBA: CSS alap k√∂nyvt√°r nem tal√°lhat√≥: {base_dir}")
        return False
    
    required_structure = {
        "01-base": ["reset.css", "variables.css", "typography.css", "global.css"],
        "02-shared": ["forms/forms.css", "buttons/buttons.css", "spacing.css", "icons.css", "animations.css", "utilities.css", "indicators.css", "fonts.css"],
        "03-layout": [],  # Optional k√∂nyvt√°r
        "04-components": [],  # Dinamikusan ellen≈ërz√∂tt
        "05-themes": ["light.css", "dark.css"],
        "06-pages": [],  # Optional k√∂nyvt√°r
        "07-vendor": []  # Optional k√∂nyvt√°r
    }
    
    all_files_exist = True
    existing_files = []
    
    for folder, files in required_structure.items():
        folder_path = base_dir / folder
        if folder_path.exists():
            for file in files:
                file_path = folder_path / file
                if file_path.exists():
                    existing_files.append(f"{folder}/{file}")
                    print(f"‚úÖ Tal√°lhat√≥: {folder}/{file}")
                else:
                    print(f"‚ö†Ô∏è  Hi√°nyzik: {folder}/{file}")
        else:
            print(f"‚ö†Ô∏è  K√∂nyvt√°r nem tal√°lhat√≥: {folder}")
    
    # Dinamikus f√°jlok keres√©se a components k√∂nyvt√°rban
    components_dir = base_dir / "04-components"
    if components_dir.exists():
        for css_file in components_dir.rglob("*.css"):
            rel_path = css_file.relative_to(base_dir)
            existing_files.append(str(rel_path))
            print(f"‚úÖ Komponens tal√°lhat√≥: {rel_path}")
    
    return existing_files

def scan_existing_css_files():
    """T√©nylegesen l√©tez≈ë CSS f√°jlok automatikus felder√≠t√©se."""
    base_dir = Path(".")  # Current directory
    css_files = []
    
    # Rekurz√≠v keres√©s minden CSS f√°jlra
    for css_file in base_dir.rglob("*.css"):
        # Skip build output files
        if css_file.name in ["main_combined_financehub.css", "main_financehub.css"]:
            continue
            
        rel_path = css_file.relative_to(base_dir).as_posix()

        # ‚Äî BLACKLIST SZ√õR√âS ‚Äî
        if any(re.search(pattern, rel_path, re.IGNORECASE) for pattern in BLACKLIST_REGEXES):
            # print(f"‚è≠Ô∏è  Skip (blacklist): {rel_path}")
            continue

        # ‚Äî WHITELIST SZ√õR√âS ‚Äî (legal√°bb az egyik prefixre illeszkedjen)
        if not any(rel_path.startswith(prefix) for prefix in WHITELIST_PREFIXES):
            # print(f"‚è≠Ô∏è  Skip (non-whitelist): {rel_path}")
            continue

        css_files.append(rel_path)
    
    # Priorit√°s szerinti rendez√©s
    priority_order = [
        "01-base/",
        "02-shared/", 
        "03-layout/",
        "04-components/",
        "05-themes/",
        "06-pages/",
        "07-vendor/"
    ]
    
    def sort_key(file_path):
        for i, prefix in enumerate(priority_order):
            if file_path.startswith(prefix):
                return (i, file_path)
        return (999, file_path)
    
    css_files.sort(key=sort_key)
    return css_files

def read_css_file(file_path):
    """CSS f√°jl biztons√°gos beolvas√°sa UTF-8 k√≥dol√°ssal."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        return content
    except Exception as e:
        print(f"‚ö†Ô∏è  Hiba a f√°jl olvas√°sakor: {file_path} - {e}")
        return ""

def optimize_css_content(content: str) -> str:
    """√Årtalmatlan whitespace-tiszt√≠t√°s, kommentek √©rintetlen√ºl.

    A kor√°bbi verzi√≥ agressz√≠ven elt√°vol√≠totta a /* ‚Ä¶ */ blokkok nyit√≥
    karaktereit, ami √©rv√©nytelen CSS-hez vezetett (a z√°r√≥ */ megmaradt,
    √≠gy a b√∂ng√©sz≈ë a komplett bundle h√°tral√©v≈ë r√©sz√©t figyelmen k√≠v√ºl
    hagyta).  Most csak a t√∂bbsz√∂r√∂s √ºres sorokat √©s a sor eleji
    felesleges sz√≥k√∂z√∂ket sz≈±rj√ºk meg ‚Äì minden kommentet eredeti form√°ban
    bennhagyunk, mert <1 KB t√∂bblet√©rt cser√©be garant√°lt a parse-biztons√°g.
    """

    # 1) T√∂bb egym√°st k√∂vet≈ë √ºres sor ‚ûú egy sor
    content = re.sub(r"\n{3,}", "\n\n", content)

    # 2) Sor eleji felesleges whitespace elt√°vol√≠t√°sa (de a kommenteket nem b√°ntjuk)
    cleaned_lines = []
    for line in content.splitlines():
        cleaned_lines.append(line.lstrip())

    return "\n".join(cleaned_lines).rstrip()

# === HTML ‚Üí USED-SELECTOR GY≈∞JT√âS (UNUSED PURGE) ===
class _SelectorExtractor(_htmlparser.HTMLParser):
    """Nagyon k√∂nny≈±s√∫ly√∫ HTML-parser, ami csak class, id, tag neveket gy≈±jt."""
    def __init__(self):
        super().__init__()
        self.classes = set()
        self.ids = set()
        self.tags = set()

    def handle_starttag(self, tag, attrs):
        self.tags.add(tag.lower())
        for attr, val in attrs:
            if attr == "class" and val:
                for cls in val.split():
                    self.classes.add(cls)
            elif attr == "id" and val:
                self.ids.add(val)


def collect_used_selectors(html_files):
    """Visszaad (used_classes, used_ids, used_tags) halmazokat."""
    extractor = _SelectorExtractor()
    for html_f in html_files:
        try:
            with open(html_f, "r", encoding="utf-8") as f:
                extractor.feed(f.read())
        except Exception as e:
            print(f"‚ö†Ô∏è  Nem tudtam beolvasni HTML-f√°jlt: {html_f} ‚Äì {e}")
    return extractor.classes, extractor.ids, extractor.tags


_CSS_RULE_RE = re.compile(r"([^{}]+)\{([^}]*)\}", re.MULTILINE)


def selector_used(selector, used_cls, used_ids, used_tags):
    selector = selector.strip()
    if not selector:
        return False
    # Keep universal selectors & at-rules
    if selector.startswith("@"):
        return True
    if selector in ["*", "html", "body"]:
        return True
    # Split complex selectors (take first simple chunk before combinator)
    first = re.split(r"\s|>|\+|~", selector)[0]
    # --- KEEP GLOBAL TOKEN BLOCKS ----------------------------------
    # FinanceHub uses CSS Custom Properties extensively under :root and
    # :root[data-theme="dark|light"] blocks.  These are critical and must
    # never be purged, even if they don't appear directly in the HTML.
    if first.startswith(':root'):
        return True

    if first.startswith('.'):  
        return first[1:] in used_cls
    if first.startswith('#'):
        return first[1:] in used_ids
    # Tag selector
    return first.lower() in used_tags

def purge_unused_css(css_text, used_cls, used_ids, used_tags):
    """Egyszer≈± regex-alap√∫ selector purge + duplik√°ci√≥ sz≈±r√©s."""
    kept_chunks = []
    seen_rules = set()
    pos = 0
    for m in _CSS_RULE_RE.finditer(css_text):
        selectors, body = m.group(1).strip(), m.group(2)
        keep = False
        for sel in selectors.split(','):
            if selector_used(sel, used_cls, used_ids, used_tags):
                keep = True
                break
        rule_text = f"{selectors}{{{body}}}"
        if keep:
            if rule_text not in seen_rules:
                kept_chunks.append(rule_text)
                seen_rules.add(rule_text)
        pos = m.end()
    return "\n".join(kept_chunks)

UTIL_CLASS_RE = re.compile(r"\.([A-Za-z0-9_:\\-]+)\s*\{([^}]+)\}", re.MULTILINE | re.DOTALL)
_APPLY_RE = re.compile(r"@apply\s+([^;]+);")

def _build_util_property_map() -> dict:
    """Aggregates utility class ‚Üí property mappings from shared utility CSS sources.

    Currently scans both:
    ‚Ä¢ 02-shared/utilities.css      ‚Üí display / flex / text / etc.
    ‚Ä¢ 02-shared/spacing.css        ‚Üí margin / padding / gap utilities

    The merger allows @apply directives such as `@apply p-4 flex` to be fully
    expanded instead of leaving /* TODO:... */ placeholders that break layout.
    """

    shared_dir = Path("02-shared")
    candidate_files = [shared_dir / "utilities.css", shared_dir / "spacing.css"]

    mapping: dict[str, str] = {}

    for css_path in candidate_files:
        if not css_path.exists():
            print(f"‚ö†Ô∏è  util source missing: {css_path}")
            continue
        try:
            css_text = css_path.read_text(encoding="utf-8")
        except Exception as e:
            print(f"‚ö†Ô∏è  Could not read {css_path.name}: {e}")
            continue

        for m in UTIL_CLASS_RE.finditer(css_text):
            cls_name = m.group(1)
            props_raw = m.group(2).strip()
            props_clean = textwrap.dedent(props_raw).strip()
            # Later files (e.g., spacing.css) should not override previous ones unless intentional
            if cls_name not in mapping:
                mapping[cls_name] = props_clean
    print(f"üó∫Ô∏è  Util map built: {len(mapping)} classes parsed from {len(candidate_files)} files")
    return mapping

def _expand_apply_directives(css_text: str, util_map: dict) -> str:
    """Replaces every `@apply ...;` directive with inline utility declarations.

    If a utility class is missing from util_map, a /* TODO */ comment is inserted so we can
    detect it easily in DevTools / future passes.
    """
    if not util_map:
        return css_text  # nothing to do

    def _replacer(match: re.Match) -> str:
        class_list = match.group(1).strip().split()
        replaced_props = []
        for cls in class_list:
            props = util_map.get(cls)
            if props:
                replaced_props.append(props)
            else:
                replaced_props.append(f"/* TODO:{cls} */")
        # Join declarations with newline + same indent as @apply line
        indent = re.match(r"^[ \t]*", css_text[:match.start()].split('\n')[-1]).group(0)
        return ("\n" + indent).join(replaced_props)

    return _APPLY_RE.sub(_replacer, css_text)

def build_css_bundle(*, dry_run: bool = False, purge_unused: bool = False, strip_apply: bool = False):
    """F≈ë CSS bundle √©p√≠t√©si folyamat.

    strip_apply: ha True, minden `@apply ...;` direkt√≠v√°t kommentre cser√©l√ºnk, hogy
    a nem-Tailwind b√∂ng√©sz≈ëk (pl. Safari) ne √°lljanak le parse-stop hib√°val.
    """
    print("üöÄ FinanceHub CSS Combined Bundle √©p√≠t√©s...")
    
    # F√°jlstrukt√∫ra valid√°l√°sa
    existing_files = validate_file_structure()
    
    # Automatikus CSS f√°jl felder√≠t√©s
    css_files = scan_existing_css_files()
    
    # Base dir dinamikus meghat√°roz√°sa
    base_dir = Path(".")  # Current directory
    
    print(f"üìÇ Alap mappa: {base_dir}")
    print(f"üìä √ñsszes f√°jl: {len(css_files)}")
    
    # CSS tartalom √∂sszegy≈±jt√©se
    combined_content = []
    
    # Header hozz√°ad√°sa
    header = f"""/* ===================================================================
   AEVOREX FINANCEHUB - COMBINED CSS BUNDLE
   Automatikusan gener√°lva: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
   Development Master: main_financehub.css ({len(css_files)} f√°jl)
   =================================================================== */

"""
    combined_content.append(header)
    
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # HTML-f√°jlok √∂sszegy≈±jt√©se a haszn√°lati list√°hoz (csak ha purge)
    used_classes = used_ids = used_tags = set()
    if purge_unused:
        html_dir = Path("..").resolve().parent  # feljebb l√©p√ºnk a css-hez k√©pest (static)
        html_candidates = list(html_dir.rglob("*.html"))
        used_classes, used_ids, used_tags = collect_used_selectors(html_candidates)
        print(f"üîé Purge m√≥d ON ‚Äì {len(html_candidates)} HTML f√°jl vizsg√°lva, "
              f"class={len(used_classes)}, id={len(used_ids)}, tag={len(used_tags)}")
    
    # Build util map once (for @apply expansion)
    util_map = _build_util_property_map()
    
    # CSS f√°jlok feldolgoz√°sa
    processed_files = 0
    for css_file in css_files:
        file_path = base_dir / css_file
        
        if file_path.exists():
            print(f"üìù Feldolgoz√°s: {css_file}")
            
            # F√°jl header
            file_header = f"\n/* === {css_file.upper()} === */\n"
            combined_content.append(file_header)
            
            # CSS tartalom
            css_content = read_css_file(file_path)
            if css_content:
                # 1) Expand @apply ‚Üí inline styles
                css_content = _expand_apply_directives(css_content, util_map)
                if strip_apply:
                    # 2) Ha maradt esetleg @apply, t√∂r√∂lj√ºk (biztons√°gi)
                    css_content = re.sub(r"\s*@apply[^;]+;", "", css_content)
                if purge_unused and css_content:
                    css_content = purge_unused_css(css_content, used_classes, used_ids, used_tags)
            processed_files += 1
            combined_content.append(css_content)
            combined_content.append("\n")
        else:
            print(f"‚ö†Ô∏è  ‚ùå Nem tal√°lhat√≥: {css_file}")
    
    print(f"üîß CSS optimaliz√°l√°s...")
    
    # Teljes tartalom √∂ssze√°ll√≠t√°sa
    final_content = "".join(combined_content)
    
    # Enyh√©bb optimaliz√°l√°s (header kommenteket megtartjuk)
    final_content = optimize_css_content(final_content)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # EXTRA STEP ‚Äì Stray "/* TODO: ... */" scaffolds cleanup
    #   Early developer scaffolding comments that begin with "/* TODO:" sometimes
    #   end up concatenated line-by-line at the top of the bundle, leaving
    #   unmatched comment tokens and (critically) leaking raw property lines
    #   outside of any selector block ‚áí WebKit parse-stop ‚Üí blank UI.
    #   We drop every SINGLE line that starts with this pattern, together with
    #   any immediate dangling terminator line "*/ */" which was produced by
    #   older formatter glitches.
    cleaned_no_todo_lines = []
    skip_next_closing = False
    for ln in final_content.splitlines():
        stripped = ln.lstrip()
        if stripped.startswith("/* TODO:"):
            skip_next_closing = True  # also skip the very next stray "*/ */" line
            continue  # drop the TODO scaffold line entirely
        # drop legacy malformed closing that immediately follows the TODO line
        if skip_next_closing and stripped.startswith("*/ */"):
            skip_next_closing = False
            continue
        # Remove legacy duplicate-rule markers like "/* body {" or "/* a:hover {" 
        if stripped.startswith("/*") and "{" in stripped:
            # Skip this line and all following lines until standalone closing '}'
            skip_block_until_closing = True
            continue
        if 'skip_block_until_closing' in locals() and skip_block_until_closing:
            # Keep skipping until we meet a line with only '}'
            if stripped.startswith('}') and stripped.strip() == '}':
                skip_block_until_closing = False
            # Continue skipping all lines inside the malformed block
            continue
        cleaned_no_todo_lines.append(ln)
    final_content = "\n".join(cleaned_no_todo_lines)

    # --- EXTRA SANITIZATION -----------------------------------------
    # A strip-apply l√©p√©s n√©ha hib√°san hagy dupla kett≈ëspont n√©lk√ºli pszeudoelemeket
    # ( pl. "*: :before,;" ), ami parse-stoppot okoz Safariban.  
    # Egyszer≈± regex-ekkel jav√≠tjuk a leggyakoribb mint√°kat.
    sanitizers = [
        (r":\s*:before", "::before"),
        (r":\s*:after", "::after"),
        (r",\s*;", ";"),
        # Elt√©vedt fejl√©c-sorok pl. "} AEVOREX ‚Ä¶" ‚Üí kommentezz√ºk ki
        (r"(?m)\}\s+([A-Za-z].*?)$", r"}\n/* \1 */"),
    ]
    for pattern, replacement in sanitizers:
        final_content = re.sub(pattern, replacement, final_content)

    # ü©π  QUICK FIX ‚Äì Drop stray standalone '}' lines before the first valid rule
    # ---------------------------------------------------------------
    #  A kor√°bbi strip / concat l√©p√©sek n√©ha mag√°nyos '}' karaktert
    #  hagytak a f√°jl legelej√©n (pl. "via Tailwind }"), ami parse-stopot
    #  okoz WebKit-alap√∫ b√∂ng√©sz≈ëkben.  Ha ez a z√°r√≥ kapcsos jel m√©g a
    #  legels≈ë nyit√≥ '{' el≈ëtt √°ll, biztons√°ggal elt√°vol√≠that√≥.
    first_open = final_content.find('{')
    if first_open != -1:
        head, tail = final_content[:first_open], final_content[first_open:]
        # T√∂r√∂lj√ºk azokat a sorokat, amelyek CSAK egy z√°r√≥ kapcsos jelet tartalmaznak
        head = re.sub(r"^\s*}\s*$(?:\n)?", "", head, flags=re.MULTILINE)
        final_content = head + tail

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # EXTRA: √°ll√≥ "*/" z√°r√≥k, amelyekhez nem tartozik nyit√≥ "/*"
    # Telekom statikus build sor√°n n√©ha bent maradnak a f√°jlok tetej√©r≈ël
    # lecsupasz√≠tott komponens-fejl√©c sorai (pl. "AEVOREX ‚Ä¶ */"), ami
    # parse-stopot okoz WebKitben.  Egyszer≈±en t√∂r√∂lj√ºk az ilyen sorokat.
    cleaned_lines = []
    open_comment = False
    for line in final_content.splitlines():
        stripped = line.strip()
        # Nyit√≥ komment detekt√°l√°sa
        if stripped.startswith("/*") and not stripped.endswith("*/"):
            open_comment = True
            cleaned_lines.append(line)
            continue
        # Z√°r√≥ komment detekt√°l√°sa
        if open_comment:
            cleaned_lines.append(line)
            if "*/" in stripped:
                open_comment = False
            continue
        # Ha a sor kiz√°r√≥lag comment-sz√∂veg √©s "*/"-re v√©gz≈ëdik, de nincs nyitva komment ‚Üí hagyjuk ki
        if stripped.endswith("*/") and "/*" not in stripped:
            continue  # DROPPED stray tail
        cleaned_lines.append(line)

    final_content = "\n".join(cleaned_lines)
    
    # --- AUTO BALANCE CURLY BRACES -----------------------------------
    # Safari (√©s m√°s b√∂ng√©sz≈ëk) a nyitott kapcsos z√°r√≥jelek ( { ) megfelel≈ë }
    # z√°r√≥k n√©lk√ºli √°llapot√°n√°l a teljes h√°tral√©v≈ë stylesheetet eldobhatj√°k.
    # Gyors ment≈ë√∂vk√©nt automatikusan p√≥toljuk a hi√°nyz√≥ z√°r√≥jeleket a f√°jl
    # legv√©g√©n.  Ez nem t√∂k√©letes, de gyakorlati megold√°s a parse-stop
    # elker√ºl√©s√©re, am√≠g fut a teljes lint/CI.

    open_braces = final_content.count('{')
    close_braces = final_content.count('}')
    if open_braces > close_braces:
        missing = open_braces - close_braces
        print(f"ü©π  {missing} hi√°nyz√≥ '}}' automatikusan p√≥tl√°sra ker√ºl a bundle v√©g√©n.")
        final_content += "\n" + ("}" * missing) + "\n"
    elif close_braces > open_braces:
        # Ritka, de jel√∂lj√ºk, ha t√∂bb a z√°r√≥ mint a nyit√≥.
        print(f"‚ö†Ô∏è  Figyelmeztet√©s: t√∂bb '}}' z√°r√≥ tal√°lhat√≥, mint '{{' nyit√≥ (extra={{close_braces - open_braces}})")
    
    # --------------------- EXTRA: remove stray top-level property lines ------------------------
    #  Ha egy tulajdons√°g (pl. "display: flex;") a <style> gy√∂k√©rszintj√©n marad, a b√∂ng√©sz≈ëk
    #  teljesen figyelmen k√≠v√ºl hagyhatj√°k a tov√°bbi deklar√°ci√≥kat.  Ez tipikusan a f√©lrement
    #  @apply ‚Üí inline kibont√°s mell√©khat√°sa volt.  Egyszer≈± heurisztik√°val kisz≈±rj√ºk azokat a
    #  sorokat, amelyek ‚Äûproperty: value;‚Äù mint√°t k√∂vetnek √âS nem egy blokk ( { } ) belsej√©ben
    #  helyezkednek el.  Az ilyen sorokat ink√°bb kommentezz√ºk ki, hogy ne ronts√°k el a parsert.

    cleaned_sanitized_lines = []
    brace_level = 0
    prop_regex = re.compile(r"^\s*[a-zA-Z_-]+\s*:\s*[^;]+;\s*$")
    skip_block_until_closing = False
    for ln in final_content.splitlines():
        stripped = ln.lstrip()

        # Skip everything inside a previously detected malformed selector block
        if skip_block_until_closing:
            if stripped.startswith('}') and stripped.strip() == '}':
                skip_block_until_closing = False  # stop skipping after closing brace line
            continue  # Skip current line

        # Detect malformed selector comment lines like "/* body {" and start skip mode
        if stripped.startswith("/*") and "{" in stripped:
            skip_block_until_closing = True
            continue  # drop this line and subsequent ones until closing brace

        # Regular comment lines (not the malformed block above) ‚Äì keep them and skip brace counting
        if stripped.startswith("/*"):
            cleaned_sanitized_lines.append(ln)
            continue  # SKIP brace counting for generic comment lines

        if brace_level == 0 and prop_regex.match(ln):
            # A deklar√°ci√≥ k√≠v√ºl van b√°rmelyik blokkb√≥l ‚Äì kommentezz√ºk ki
            cleaned_sanitized_lines.append(f"/* ~~FIXME stray property~~ {ln.strip()} */")
            continue

        cleaned_sanitized_lines.append(ln)
        
        # Csak EZUT√ÅN friss√≠tj√ºk a blokk-m√©lys√©get erre a sorra n√©zve
        brace_level += ln.count('{') - ln.count('}')

    final_content = "\n".join(cleaned_sanitized_lines)
    
    # Kimeneti f√°jl √≠r√°sa
    try:
        # Legacy bundle is now suffixed with .legacy.css to avoid being imported by the new Vite+Tailwind pipeline
        output_path = Path("main_combined_financehub.legacy.css")
        print(f"üéØ Kimeneti f√°jl: {output_path}")
        
        if purge_unused and not dry_run:
            # Already pointing to legacy bundle ‚Äì no need for compatibility copy
            original_path = output_path

        if dry_run:
            print("üîé DRY-RUN: Kimeneti f√°jl nem ker√ºl ki√≠r√°sra (ellen√µrz√µ m√≥d)")
        else:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(final_content)
        
        # Statisztik√°k
        file_size = output_path.stat().st_size if output_path.exists() else 0
        lines_count = len(final_content.split('\n'))
        
        print(f"\nüéâ ‚úÖ CSS BUILD SIKERES!")
        print(f"üìÑ Feldolgozott f√°jlok: {processed_files}/{len(css_files)}")
        print(f"üì¶ Kimeneti f√°jl: {output_path}")
        print(f"üìè M√©ret: {file_size:,} byte")
        print(f"üìú Sorok sz√°ma: {lines_count:,}")
        print(f"‚ö° CSS optimaliz√°l√°s: AKT√çV")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Hiba a f√°jl √≠r√°sakor: {e}")
        return False

def main():
    """F≈ë entry point."""
    print("=" * 60)
    print("üèóÔ∏è  AEVOREX FINANCEHUB CSS BUILDER")
    print("=" * 60)
    
    # Munkak√∂nyvt√°r ellen≈ërz√©se
    current_dir = Path.cwd()
    print(f"üìÅ Munkak√∂nyvt√°r: {current_dir}")
    
    # Ha m√°r a css mapp√°ban vagyunk, egyb≈ël futtatjuk a buildet
    if current_dir.name == "css" and (current_dir / "01-base").exists():
        print(f"‚úÖ CSS k√∂nyvt√°rban vagyunk: {current_dir}")
        
        # DUPLIK√ÅCI√ì DETEKT√ÅL√ÅS FUTTAT√ÅSA (k√∂telez≈ë minden build el≈ëtt)
        print("\n" + "="*60)
        duplicate_count = detect_duplicates_in_css_files()
        print("="*60)
        
        # Build futtat√°sa (duplik√°ci√≥k ellen√©re is)
        print("\nüöÄ BUILD FOLYTAT√ÅSA...")
        if duplicate_count > 0:
            print(f"‚ö†Ô∏è  FIGYELEM: {duplicate_count} duplik√°ci√≥val folytatva!")
            print("üí° Javaslat: Jav√≠tsd ki a duplik√°ci√≥kat a clean build √©rdek√©ben.\n")
        
        # --- ARGUMENTUMOK FELDOLGOZ√ÅSA ---
        dry_run_flag = "--dry-run" in sys.argv or "--dryrun" in sys.argv or "-n" in sys.argv
        purge_flag = "--purge" in sys.argv
        strip_apply_flag = "--strip-apply" in sys.argv or "--strip_apply" in sys.argv

        success = build_css_bundle(dry_run=dry_run_flag, purge_unused=purge_flag, strip_apply=strip_apply_flag)
        
        if success:
            if duplicate_count > 0:
                print(f"\nüéØ BUILD BEFEJEZVE - DE {duplicate_count} DUPLIK√ÅCI√ì MARADT! ‚ö†Ô∏è")
                print("üõ†Ô∏è  A f√°jl haszn√°lhat√≥, de nem optim√°lis.")
                print("üí° K√∂vetkez≈ë l√©p√©s: duplik√°ci√≥k manu√°lis tiszt√≠t√°sa.")
            else:
                print("\nüéØ BUILD BEFEJEZVE - Ready for production! üöÄ")
            return True
        else:
            print("\n‚ùå BUILD FAILED - Ellen≈ërizd a hib√°kat!")
            return False
    
    # CSS k√∂nyvt√°r keres√©se
    css_dir = None
    possible_paths = [
        Path("Aevorex_codes/modules/financehub/frontend/static/css"),
        Path("modules/financehub/frontend/static/css"),
        Path("frontend/static/css"),
        Path("static/css"),
        Path("css")
    ]
    
    for path in possible_paths:
        if path.exists():
            css_dir = path
            break
    
    if not css_dir:
        print("‚ùå CSS k√∂nyvt√°r nem tal√°lhat√≥! Ellen≈ërizd a munkak√∂nyvt√°rat.")
        print(f"Keresett √∫tvonalak: {[str(p) for p in possible_paths]}")
        return False
    
    print(f"‚úÖ CSS k√∂nyvt√°r tal√°lva: {css_dir}")
    
    # V√°lt√°s a 'css' k√∂nyvt√°rba, hogy a whitelist prefixek stimmeljenek
    if Path.cwd() != css_dir.resolve():
        os.chdir(css_dir)
        print(f"üìÇ V√°lt√°s CSS k√∂nyvt√°rba: {Path.cwd()}")
    
    # DUPLIK√ÅCI√ì DETEKT√ÅL√ÅS FUTTAT√ÅSA (k√∂telez≈ë minden build el≈ëtt)
    print("\n" + "="*60)
    duplicate_count = detect_duplicates_in_css_files()
    print("="*60)
    
    # Build futtat√°sa (duplik√°ci√≥k ellen√©re is)
    print("\nüöÄ BUILD FOLYTAT√ÅSA...")
    if duplicate_count > 0:
        print(f"‚ö†Ô∏è  FIGYELEM: {duplicate_count} duplik√°ci√≥val folytatva!")
        print("üí° Javaslat: Jav√≠tsd ki a duplik√°ci√≥kat a clean build √©rdek√©ben.\n")
    
    # --- ARGUMENTUMOK FELDOLGOZ√ÅSA ---
    dry_run_flag = "--dry-run" in sys.argv or "--dryrun" in sys.argv or "-n" in sys.argv
    purge_flag = "--purge" in sys.argv
    strip_apply_flag = "--strip-apply" in sys.argv or "--strip_apply" in sys.argv

    success = build_css_bundle(dry_run=dry_run_flag, purge_unused=purge_flag, strip_apply=strip_apply_flag)
    
    if success:
        if duplicate_count > 0:
            print(f"\nüéØ BUILD BEFEJEZVE - DE {duplicate_count} DUPLIK√ÅCI√ì MARADT! ‚ö†Ô∏è")
            print("üõ†Ô∏è  A f√°jl haszn√°lhat√≥, de nem optim√°lis.")
            print("üí° K√∂vetkez≈ë l√©p√©s: duplik√°ci√≥k manu√°lis tiszt√≠t√°sa.")
        else:
            print("\nüéØ BUILD BEFEJEZVE - Ready for production! üöÄ")
        return True
    else:
        print("\n‚ùå BUILD FAILED - Ellen≈ërizd a hib√°kat!")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 